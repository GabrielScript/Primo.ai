# app.py
# ----------------------------------------------------------------------------
# ARQUITETURA: RAG Local (Git) + DeepSeek + Persist√™ncia de Chat (Supabase)
# AUTOR: Ph.D. Assistant & User
# VERS√ÉO: 9.0 (Gold Master - Cloud Ready)
# ----------------------------------------------------------------------------

import os
import json
import logging
import math
import re
import time
import pickle
import uuid
from collections import Counter
from datetime import datetime
from typing import List, Dict, Tuple, Optional

import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential
from supabase import create_client, Client

# ============================================================================
# 1. CONFIGURA√á√ÉO & HIPERPAR√ÇMETROS
# ============================================================================

load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- CAMINHOS DE PERSIST√äNCIA (MEM√ìRIA EST√ÅTICA) ---
# No Streamlit Cloud, isso vir√° do seu reposit√≥rio Git
MEMORY_DIR = "primo_memory"
DB_FILE = os.path.join(MEMORY_DIR, "knowledge_base.parquet")
INDEX_FILE = os.path.join(MEMORY_DIR, "bm25_index.pkl")

# --- BRANDING ---
# Certifique-se que esses arquivos est√£o na raiz do repo
LOGO_PATH = "Primo_LOGO-removebg-preview.png" 
LOGO_PATH2 = "Logo_primo.png"

# --- TUNING DE SEGURAN√áA & RETRIEVAL ---
MAX_SAFE_TOKENS = 80000     
MAX_SAFE_CHARS = MAX_SAFE_TOKENS * 4 
MAX_RETRIEVED_DOCS = 5      
CONTEXT_WINDOW_SIZE = 2      

LLM_MODEL = "deepseek-chat"
TEMPERATURE = 0.3            
BASE_URL = "https://api.deepseek.com"

# --- SETUP SUPABASE (MEM√ìRIA DIN√ÇMICA) ---
# Tenta pegar dos secrets (Cloud) ou vari√°veis de ambiente (Local)
SUPABASE_URL = st.secrets.get("SUPABASE_URL") or os.getenv("SUPABASE_URL")
SUPABASE_KEY = st.secrets.get("SUPABASE_KEY") or os.getenv("SUPABASE_KEY")

# ============================================================================
# 2. ALGORITMO BM25 (CRUCIAL ESTAR AQUI PARA O PICKLE FUNCIONAR)
# ============================================================================

class SimpleBM25:
    """Implementa√ß√£o leve do BM25. Otimizada para ser 'picklable'."""
    def __init__(self, corpus: List[str]):
        self.corpus_size = len(corpus)
        self.avgdl = 0
        self.doc_freqs = []
        self.idf = {}
        self.doc_len = []
        self.k1 = 1.5
        self.b = 0.75
        self.stopwords = {
            'de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'n√£o', 'uma', 'os', 'no', 
            'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', '√†', 'seu', 'sua', 
            'ou', 'quando', 'muito', 'nos', 'j√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 
            'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'voc√™', 
            'essa', 'num', 'nem', 'suas', 'meu', '√†s', 'minha', 'numa', 'pelos', 'elas', 'qual', 'n√≥s', 
            'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'voc√™s', 'vos', 'lhes', 
            'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 
            'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 
            'estou', 'est√°', 'estamos', 'est√£o', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 
            'est√°vamos', 'estavam', 'estivera', 'estiv√©ramos', 'haja', 'hajamos', 'hajam', 'houve', 
            'houvemos', 'houveram', 'houvera', 'houv√©ramos', 'seja', 'sejamos', 'sejam', 'fosse', 
            'f√¥ssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'ser√°', 'seremos', 'ser√£o', 'seria', 
            'ser√≠amos', 'seriam', 'tenho', 'tem', 'temos', 't√©m', 'tinha', 't√≠nhamos', 'tinham', 'tive', 
            'teve', 'tivemos', 'tiveram', 'tivera', 'tiv√©ramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 
            'tiv√©ssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'ter√°', 'teremos', 'ter√£o', 
            'teria', 'ter√≠amos', 'teriam'
        }
        self._initialize(corpus)

    def _initialize(self, corpus):
        total_length = 0
        for document in corpus:
            tokens = self._tokenize(document)
            self.doc_len.append(len(tokens))
            total_length += len(tokens)
            frequencies = Counter(tokens)
            self.doc_freqs.append(frequencies)
            for token in frequencies:
                self.idf[token] = self.idf.get(token, 0) + 1
        
        self.avgdl = total_length / self.corpus_size if self.corpus_size > 0 else 1
        for token, freq in self.idf.items():
            self.idf[token] = math.log(1 + (self.corpus_size - freq + 0.5) / (freq + 0.5))

    def _tokenize(self, text: str) -> List[str]:
        text = str(text).lower()
        text = re.sub(r'[^\w\s]', '', text) 
        tokens = text.split()
        return [t for t in tokens if t not in self.stopwords and len(t) > 2]

    def get_scores(self, query: str) -> List[float]:
        query_tokens = self._tokenize(query)
        scores = [0.0] * self.corpus_size
        for i in range(self.corpus_size):
            doc_len = self.doc_len[i]
            freqs = self.doc_freqs[i]
            for token in query_tokens:
                if token not in freqs: continue
                freq = freqs[token]
                numerator = self.idf.get(token, 0) * freq * (self.k1 + 1)
                denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)
                scores[i] += numerator / denominator
        return scores

# ============================================================================
# 3. GEST√ÉO DE CONEX√ïES E DADOS
# ============================================================================

@st.cache_resource
def get_supabase_client():
    if not SUPABASE_URL or not SUPABASE_KEY:
        return None
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception as e:
        st.error(f"Erro na conex√£o Supabase: {e}")
        return None

@st.cache_resource
def get_llm_client():
    # Tenta pegar a chave do Secrets ou do .env
    api_key = st.secrets.get("DEEPSEEK_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        st.error("Chave da API DeepSeek n√£o encontrada.")
        return None
    return OpenAI(base_url=BASE_URL, api_key=api_key)

def load_memory_from_disk() -> Tuple[Optional[pd.DataFrame], Optional[SimpleBM25]]:
    """Carrega a mem√≥ria est√°tica (Git)."""
    if os.path.exists(DB_FILE) and os.path.exists(INDEX_FILE):
        try:
            df = pd.read_parquet(DB_FILE)
            with open(INDEX_FILE, 'rb') as f:
                bm25 = pickle.load(f)
            return df, bm25
        except Exception as e:
            st.warning(f"Erro ao carregar mem√≥ria do disco: {e}")
            return None, None
    return None, None

# ============================================================================
# 4. GEST√ÉO DE CHAT (SUPABASE)
# ============================================================================

def load_chat_history() -> Dict:
    """Baixa o hist√≥rico do Supabase."""
    supabase = get_supabase_client()
    if not supabase: return {}
    
    try:
        response = supabase.table("chat_sessions").select("*").order("last_updated", desc=True).execute()
        history = {}
        for row in response.data:
            history[row['session_id']] = {
                "title": row['title'],
                "timestamp": row['last_updated'],
                "messages": row['messages']
            }
        return history
    except Exception as e:
        # Silencia erro se for s√≥ falta de tabela na primeira vez
        print(f"Aviso Supabase: {e}")
        return {}

def save_chat_session_remote(session_id: str, session_data: Dict):
    """Salva/Atualiza sess√£o no Supabase."""
    supabase = get_supabase_client()
    if not supabase: return

    try:
        data = {
            "session_id": session_id,
            "title": session_data["title"],
            "messages": session_data["messages"],
            "last_updated": datetime.now().isoformat()
        }
        supabase.table("chat_sessions").upsert(data).execute()
    except Exception as e:
        print(f"Erro ao salvar remoto: {e}")

def create_new_chat_session():
    new_id = str(uuid.uuid4())
    new_data = {
        "title": "Nova Conversa",
        "timestamp": datetime.now().isoformat(),
        "messages": []
    }
    st.session_state.all_chats[new_id] = new_data
    st.session_state.active_session_id = new_id
    save_chat_session_remote(new_id, new_data)

def delete_chat_session(session_id):
    supabase = get_supabase_client()
    if session_id in st.session_state.all_chats:
        del st.session_state.all_chats[session_id]
    
    if supabase:
        try:
            supabase.table("chat_sessions").delete().eq("session_id", session_id).execute()
        except Exception as e:
            st.error(f"Erro ao deletar da nuvem: {e}")

    # Redirecionamento inteligente
    remaining_ids = list(st.session_state.all_chats.keys())
    if remaining_ids:
        # Ordena para pegar o mais recente
        sorted_ids = sorted(st.session_state.all_chats.items(), key=lambda x: x[1]['timestamp'], reverse=True)
        st.session_state.active_session_id = sorted_ids[0][0]
    else:
        create_new_chat_session()
    
    st.rerun()

# ============================================================================
# 5. MOTOR DE BUSCA E GERA√á√ÉO (CORE)
# ============================================================================

def retrieve_context(query: str, df: pd.DataFrame, bm25: SimpleBM25) -> str:
    if df is None or bm25 is None: return ""
    
    # Valida√ß√£o de Seguran√ßa
    if len(df) != bm25.corpus_size:
        return ""

    scores = bm25.get_scores(query)
    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:MAX_RETRIEVED_DOCS]
    top_indices = [i for i in top_indices if scores[i] > 1.0]

    if not top_indices: return ""

    expanded_indices = set()
    for idx in top_indices:
        start = max(0, idx - CONTEXT_WINDOW_SIZE)
        end = min(len(df), idx + CONTEXT_WINDOW_SIZE + 1)
        original_source = df.iloc[idx]['source_title']
        for i in range(start, end):
            if df.iloc[i]['source_title'] == original_source:
                expanded_indices.add(i)

    final_indices = sorted(list(expanded_indices))
    context_blocks = []
    current_chars = 0
    
    for idx in final_indices:
        row = df.iloc[idx]
        block = f"\nüì∫ FONTE: {row['source_title']} ({row['source_url']})\n- {row['clean_text']}\n"
        if current_chars + len(block) > MAX_SAFE_CHARS:
            context_blocks.append("\n‚ö†Ô∏è [SISTEMA: CONTEXTO LIMITE ATINGIDO] ‚ö†Ô∏è")
            break
        context_blocks.append(block)
        current_chars += len(block)

    return "".join(context_blocks)

@retry(stop=stop_after_attempt(2), wait=wait_exponential(multiplier=1, min=2, max=5))
def generate_response(query: str, context: str):
    system_persona = """
     Voc√™ √© o G√™meo Digital do Thiago Nigro.
        DIRETRIZES:
        1. Seja detalhista e use o CONTEXTO fornecido.
        2. Cite os v√≠deos/fontes do contexto.
        3. Use a personalidade do Thiago (Skin in the game, longo prazo)
        4. Seja extremamente detalhista, profundo e abrangente no m√°ximo que voc√™ puder.
        5. Use apenas o CONTEXTO mais recente fornecido (N√£o use o conhecimento geral de treinamento do modelo) para responder.
        6. Sempre referencie nas suas respostas, o video mais recente utilizado para a mesma.
        7. Se o contexto for cortado, use o que tem dispon√≠vel.
        8. Seja vision√°rio, pr√°tico e conselheiro ou coach financeiro.
        9. Incorpore a ess√™ncia intr√≠nseca da alma do Thiago Nigro, use seu jeito de falar, suas g√≠rias e sua personalidade √∫nica. Copie-o, Imite-o.
    """
    
    full_prompt = f"CONTEXTO RECUPERADO:\n{context}\n\nPERGUNTA DO PRIMO:\n{query}"
    client = get_llm_client()
    if not client: return None

    stream = client.chat.completions.create(
        model=LLM_MODEL,
        messages=[{"role": "system", "content": system_persona}, {"role": "user", "content": full_prompt}],
        stream=True,
        temperature=TEMPERATURE,
        max_tokens=8000
    )
    return stream

# ============================================================================
# 6. UI PRINCIPAL
# ============================================================================

def main():
    st.set_page_config(
        page_title="Primo.AI | G√™meo Digital", 
        page_icon=LOGO_PATH2, 
        layout="wide"
    )
    
    st.markdown("""
        <style>
            .stApp { background-color: #0e1117; color: #f0f2f6; } 
            .stChatMessage { background-color: #1f2937; border: 1px solid #374151; border-radius: 12px; }
            [data-testid="stSidebarNav"] { display: none; }
            div[data-testid="stSidebar"] button {
                text-align: left;
                width: 100%;
                border-radius: 8px;
                margin-bottom: 4px;
                padding: 8px 12px;
                background-color: #262730;
                border: 1px solid transparent;
            }
            div[data-testid="stSidebar"] button:hover {
                border-color: #fca311;
                background-color: #31333f;
            }
        </style>
    """, unsafe_allow_html=True)

    # --- LOADING INICIAL ---
    if "db" not in st.session_state:
        # Carrega Mem√≥ria Est√°tica (Git)
        df_disk, bm25_disk = load_memory_from_disk()
        st.session_state.db = df_disk
        st.session_state.bm25 = bm25_disk
    
    if "all_chats" not in st.session_state:
        # Carrega Mem√≥ria Din√¢mica (Supabase)
        st.session_state.all_chats = load_chat_history()
    
    if "active_session_id" not in st.session_state:
        if st.session_state.all_chats:
            sorted_chats = sorted(st.session_state.all_chats.items(), key=lambda x: x[1]['timestamp'], reverse=True)
            st.session_state.active_session_id = sorted_chats[0][0]
        else:
            create_new_chat_session()

    # --- SIDEBAR ---
    
    with st.sidebar:
        c1, c2 = st.columns([1, 4])
        with c1:
            try: st.image(LOGO_PATH, width=50)
            except: st.write("ü§ñ")
        with c2:
            st.title("Primo.AI")
            st.caption("G√™meo Digital do Thiago Nigro | Desenvolvido por Gabriel Estrela")
        
        if st.button("‚ûï Nova Conversa", type="primary", use_container_width=True):
            create_new_chat_session()
            st.rerun()
            
        st.markdown("---")
        st.caption("HIST√ìRICO")

        # Lista de conversas ordenadas
        sorted_chats = sorted(
            st.session_state.all_chats.items(), 
            key=lambda x: x[1].get('timestamp', ''), 
            reverse=True
        )

        for cid, cdata in sorted_chats:
            is_active = (cid == st.session_state.active_session_id)
            title = cdata.get('title', 'Conversa sem t√≠tulo')
            btn_label = f"{'üü¢' if is_active else 'üí¨'} {title}"
            
            if st.button(btn_label, key=f"btn_{cid}"):
                st.session_state.active_session_id = cid
                st.rerun()
        
        st.markdown("---")
        if st.button("üóëÔ∏è Apagar Chat Atual"):
            delete_chat_session(st.session_state.active_session_id)

    # --- CHAT AREA ---
    if st.session_state.active_session_id not in st.session_state.all_chats:
        create_new_chat_session()
        st.rerun()

    current_id = st.session_state.active_session_id
    current_chat = st.session_state.all_chats[current_id]
    messages = current_chat["messages"]

    # Renderiza mensagens anteriores
    for msg in messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    # Input
    if prompt := st.chat_input("Pergunte ao Primo..."):
        # Se n√£o tiver mem√≥ria carregada
        if st.session_state.db is None:
            st.error("‚ö†Ô∏è Mem√≥ria n√£o encontrada. Verifique se a pasta 'primo_memory' est√° no GitHub.")
            st.stop()

        # 1. Usu√°rio
        messages.append({"role": "user", "content": prompt})
        st.session_state.all_chats[current_id]["messages"] = messages
        
        # Auto-t√≠tulo na primeira mensagem
        if len(messages) == 1:
            st.session_state.all_chats[current_id]["title"] = (prompt[:30] + "...") if len(prompt) > 30 else prompt
        
        st.session_state.all_chats[current_id]["timestamp"] = datetime.now().isoformat()
        save_chat_session_remote(current_id, st.session_state.all_chats[current_id])
        
        with st.chat_message("user"): st.markdown(prompt)

        # 2. Assistente
        with st.chat_message("assistant"):
            resp_container = st.empty()
            with st.spinner("Consultando livros e v√≠deos..."):
                context = retrieve_context(prompt, st.session_state.db, st.session_state.bm25)
            
            if not context:
                msg_fail = "Primo, n√£o achei nada espec√≠fico sobre isso nos meus arquivos. Tem certeza que j√° me ensinou?"
                resp_container.markdown(msg_fail)
                messages.append({"role": "assistant", "content": msg_fail})
                st.session_state.all_chats[current_id]["messages"] = messages
                save_chat_session_remote(current_id, st.session_state.all_chats[current_id])
            else:
                full_res = ""
                try:
                    stream = generate_response(prompt, context)
                    if stream:
                        for chunk in stream:
                            content = chunk.choices[0].delta.content or ""
                            full_res += content
                            resp_container.markdown(full_res + "‚ñå")
                        
                        resp_container.markdown(full_res)
                        messages.append({"role": "assistant", "content": full_res})
                        st.session_state.all_chats[current_id]["messages"] = messages
                        save_chat_session_remote(current_id, st.session_state.all_chats[current_id])
                        
                        if len(messages) <= 2: st.rerun()
                except Exception as e:
                    st.error(f"Erro na API: {e}")

if __name__ == "__main__":
    main()