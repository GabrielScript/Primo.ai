# Primo.AI: O G√™meo Digital do Primo Rico

## Descri√ß√£o do Projeto

O Primo.AI √© um projeto inovador que simula um "G√™meo Digital" do Thiago Nigro (o "Primo Rico"), utilizando t√©cnicas avan√ßadas de Processamento de Linguagem Natural (PLN) e Gera√ß√£o Aumentada por Recupera√ß√£o (RAG). A aplica√ß√£o permite interagir com uma intelig√™ncia artificial que responde a perguntas sobre investimentos, carreira e neg√≥cios, emulando o estilo, o conhecimento e a personalidade de Thiago Nigro.

Este projeto √© dividido em duas partes principais:

1.  **Coleta e Processamento de Transcri√ß√µes (`Transcript_Channel.py`):** Um script robusto para extrair transcri√ß√µes de v√≠deos do YouTube de um canal espec√≠fico (neste caso, o do Primo Rico). Essas transcri√ß√µes formam a base de conhecimento sobre a qual o G√™meo Digital √© treinado e consultado.
2.  **Aplica√ß√£o Interativa (`app.py`):** Uma interface web constru√≠da com Streamlit que carrega as transcri√ß√µes (ou outros documentos como PDF, TXT, JSON, Parquet) e permite aos usu√°rios fazerem perguntas. A aplica√ß√£o utiliza um algoritmo BM25 otimizado para recuperar informa√ß√µes relevantes do vasto corpus de conhecimento e, em seguida, utiliza um Large Language Model (LLM) (DeepSeek) para gerar respostas coerentes e personalizadas, mantendo a persona do Primo Rico.

O objetivo √© fornecer uma ferramenta interativa para acessar o conhecimento e a perspectiva de Thiago Nigro de forma r√°pida e eficiente.

## Funcionalidades

### G√™meo Digital (Primo.AI - `app.py`)
*   **Interface Conversacional:** Interaja com o G√™meo Digital do Primo Rico atrav√©s de um chat intuitivo, simulando uma conversa real.
*   **Base de Conhecimento RAG:** Utiliza um sistema de Recupera√ß√£o Aumentada por Gera√ß√£o (RAG) para buscar informa√ß√µes relevantes de uma base de dados robusta antes de gerar respostas.
*   **Suporte a M√∫ltiplos Formatos de Documentos:** Carregue conhecimentos em diversos formatos, incluindo JSON, Parquet, PDF e TXT.
*   **BM25 Otimizado:** Incorpora um algoritmo BM25 customizado com stopwords em portugu√™s para uma recupera√ß√£o de contexto precisa e eficiente.
*   **Persona Personalizada:** O LLM √© configurado para emular a linguagem, o tom e a personalidade de Thiago Nigro, fornecendo conselhos financeiros e de neg√≥cios com seu estilo caracter√≠stico.
*   **Gest√£o de Contexto Robusta:** Implementa "freios de seguran√ßa" para gerenciar o tamanho do contexto enviado ao LLM, otimizando o uso de tokens e prevenindo sobrecarga.
*   **Hist√≥rico de Chat:** Permite visualizar e baixar o hist√≥rico completo da conversa para refer√™ncia futura.
*   **Limpeza de Chat:** Op√ß√£o para reiniciar a conversa a qualquer momento.
*   **Branding Visual:** Interface com elementos visuais que remetem √† marca "Primo Rico".

### Coletor de Transcri√ß√µes (Scraper - `Transcript_Channel.py`)
*   **Extra√ß√£o de Transcri√ß√µes de YouTube:** Automatiza a coleta de transcri√ß√µes de v√≠deos de qualquer canal do YouTube (mediante configura√ß√£o do `CHANNEL_HANDLE`).
*   **API Robusta:** Utiliza a API `scrapecreators.com` com tratamento de retries e exponencial backoff para garantir a resili√™ncia na coleta de dados.
*   **Par√¢metros Configur√°veis:** Defina o n√∫mero m√°ximo de v√≠deos a serem coletados e a ordem de busca (mais recentes ou mais populares).
*   **Gera√ß√£o de JSON:** Salva as transcri√ß√µes coletadas (juntamente com metadados como t√≠tulo, URL, visualiza√ß√µes, etc.) em um arquivo JSON estruturado, pronto para ser consumido pela aplica√ß√£o principal.
*   **Barra de Progresso:** Feedback visual sobre o processo de coleta atrav√©s de barras de progresso (`tqdm`).

## Tecnologias Utilizadas

*   **Python 3.x**
*   **Streamlit:** Para a constru√ß√£o da interface web interativa (`app.py`).
*   **DeepSeek API (via OpenAI Python Client):** Como o Large Language Model (LLM) subjacente para gera√ß√£o de texto.
*   **Pandas:** Para manipula√ß√£o e processamento de dados.
*   **PyPDF2:** Para leitura de arquivos PDF.
*   **python-dotenv:** Para gerenciamento de vari√°veis de ambiente.
*   **requests:** Para requisi√ß√µes HTTP na coleta de transcri√ß√µes.
*   **urllib3 (Retry):** Para resili√™ncia em requisi√ß√µes HTTP.
*   **tqdm:** Para barras de progresso visuais durante a coleta de dados.
*   **ScrapeCreators API:** Servi√ßo externo utilizado para extrair transcri√ß√µes do YouTube (`Transcript_Channel.py`).

## Configura√ß√£o e Instala√ß√£o

Siga os passos abaixo para configurar e executar o projeto em sua m√°quina local.

### Pr√©-requisitos

*   **Python 3.x**
*   **Gerenciador de Pacotes pip**

### 1. Clonar o Reposit√≥rio

```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd Primo Rico MVP
```

### 2. Criar e Ativar o Ambiente Virtual (Recomendado)

```bash
python -m venv .venv
# No Windows
.venv\Scripts\activate
# No macOS/Linux
source .venv/bin/activate
```

### 3. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configurar Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto e adicione suas chaves de API:

```
# .env
DEEPSEEK_API_KEY="SUA_CHAVE_DE_API_DEEPSEEK"
SCRAPECREATORS_API_KEY="SUA_CHAVE_DE_API_SCRAPECREATORS"
```

*   Obtenha sua `DEEPSEEK_API_KEY` em [DeepSeek AI](https://www.deepseek.com/).
*   Obtenha sua `SCRAPECREATORS_API_KEY` em [ScrapeCreators](https://scrapecreators.com/).

### 5. Configurar o Streamlit (Opcional, para personaliza√ß√£o)

O Streamlit permite a cria√ß√£o de um arquivo `secrets.toml` e `config.toml` dentro de uma pasta `.streamlit` para gerenciar segredos e configura√ß√µes da aplica√ß√£o.

**`.streamlit/secrets.toml`:**
```toml
# secrets.toml
DEEPSEEK_API_KEY="SUA_CHAVE_DE_API_DEEPSEEK"
SCRAPECREATORS_API_KEY="SUA_CHAVE_DE_API_SCRAPECREATORS"
```
**`.streamlit/config.toml`:**
(Este arquivo j√° deve existir, pode ser editado para customiza√ß√µes adicionais do Streamlit)
```toml
[server]
port = 8501
headless = true

[global]
enableCORS = true
enableXsrfProtection = true

[client]
toolbarMode = "minimal"

[theme]
base="dark"
primaryColor="#F63366"
backgroundColor="#0E1117"
secondaryBackgroundColor="#262730"
textColor="#FAFAFA"
font="sans serif"
```

**Nota:** As chaves de API podem ser carregadas tanto pelo `.env` (para scripts gerais e ambiente local) quanto pelo `secrets.toml` (para Streamlit, especialmente em deploy). Recomenda-se usar `.env` para desenvolvimento local e `secrets.toml` para deployments do Streamlit.

## Como Usar

O projeto consiste em duas partes principais: o script de coleta de transcri√ß√µes e a aplica√ß√£o interativa.

### 1. Coletando Transcri√ß√µes (Usando `Transcript_Channel.py`)

Antes de usar a aplica√ß√£o principal, voc√™ precisar√° de uma base de conhecimento. As transcri√ß√µes do YouTube s√£o um excelente ponto de partida.

1.  **Edite `Transcript_Channel.py`:** Abra o arquivo `Transcript_Channel.py` e configure as seguintes vari√°veis:
    *   `SCRAPECREATORS_API_KEY`: Certifique-se de que sua chave de API est√° configurada no `.env` ou diretamente no script.
    *   `CHANNEL_HANDLE`: Defina o "handle" do canal do YouTube que deseja transcrever (ex: `"primorico"`).
    *   `MAX_VIDEOS`: Especifique quantos v√≠deos voc√™ quer transcrever.
    *   `SORT_BY`: Escolha entre `"latest"` (mais recentes) ou `"popular"` (mais populares).

2.  **Execute o script:**
    ```bash
    python Transcript_Channel.py
    ```
    O script ir√° coletar as transcri√ß√µes e salvar√° um arquivo JSON (ex: `transcricoes_primorico_17.json`) na pasta raiz do projeto. Este arquivo ser√° sua base de conhecimento para o Primo.AI.

### 2. Iniciando a Aplica√ß√£o Primo.AI (Usando `app.py`)

Ap√≥s ter seu arquivo JSON de transcri√ß√µes (ou outros documentos), voc√™ pode iniciar a aplica√ß√£o interativa:

1.  **Execute a aplica√ß√£o Streamlit:**
    ```bash
    streamlit run app.py
    ```
    Isso abrir√° a aplica√ß√£o em seu navegador padr√£o.

2.  **Upload de Documentos:**
    *   Na barra lateral esquerda, na se√ß√£o "üìÇ Base de Conhecimento", clique em "Upload Arquivos".
    *   Selecione o arquivo JSON gerado pelo `Transcript_Channel.py` ou qualquer outro arquivo de texto (`.txt`), PDF (`.pdf`) ou Parquet (`.parquet`) que contenha informa√ß√µes relevantes. Voc√™ pode fazer upload de m√∫ltiplos arquivos.
    *   Aguarde enquanto a aplica√ß√£o processa os documentos e constr√≥i o √≠ndice de busca. Uma barra de progresso ser√° exibida.

3.  **Interagindo com o G√™meo Digital:**
    *   Uma vez que os documentos forem processados, voc√™ pode come√ßar a fazer perguntas na caixa de chat na parte inferior da tela.
    *   O Primo.AI buscar√° informa√ß√µes no seu conhecimento carregado e gerar√° uma resposta.

4.  **Gerenciando a Conversa:**
    *   Na barra lateral, voc√™ encontrar√° op√ß√µes para "üì• Baixar Hist√≥rico" (salva a conversa atual em um arquivo de texto) e "üóëÔ∏è Limpar Chat" (reinicia a conversa).

## Estrutura do C√≥digo

### `app.py` - Aplica√ß√£o Principal do G√™meo Digital

Este arquivo cont√©m a l√≥gica central da aplica√ß√£o web interativa Streamlit, que permite aos usu√°rios interagir com o G√™meo Digital do Thiago Nigro.

**Principais Se√ß√µes:**

*   **1. Configura√ß√£o & Hiperpar√¢metros:** Define vari√°veis globais para a aplica√ß√£o, como `LOGO_PATH`, chaves de API (carregadas via `dotenv`), o modelo de LLM (`deepseek-chat`), temperatura, e limites de seguran√ßa (`MAX_SAFE_TOKENS`, `MAX_SAFE_CHARS`) para o contexto.
*   **2. Algoritmo BM25 Otimizado:** Implementa uma vers√£o leve do algoritmo BM25 (`SimpleBM25`) para recupera√ß√£o de informa√ß√µes. Este algoritmo √© otimizado com uma lista de stopwords em portugu√™s para melhorar a relev√¢ncia dos resultados da busca dentro do corpus de documentos.
*   **3. Camada de Dados & Processamento (`load_and_index_data`):** Gerencia o carregamento e a indexa√ß√£o dos arquivos de dados (JSON, Parquet, PDF, TXT) que formam a base de conhecimento do LLM. Realiza a normaliza√ß√£o, limpeza de texto, identifica√ß√£o de colunas relevantes e cria√ß√£o do √≠ndice BM25 a partir do corpus consolidado. Utiliza `st.cache_data` para otimizar o desempenho.
*   **4. Busca Segura (Safety Brakes - `retrieve_context`):** Fun√ß√£o respons√°vel por buscar no corpus os trechos de texto mais relevantes (`MAX_RETRIEVED_DOCS`) para a pergunta do usu√°rio, utilizando o BM25. Inclui l√≥gica para expandir o contexto com base em uma "janela de contexto" (`CONTEXT_WINDOW_SIZE`) e garante que o contexto n√£o exceda `MAX_SAFE_CHARS`, prevenindo estouros de token no LLM. Tamb√©m filtra contextos por fonte para evitar mistura indevida de informa√ß√µes.
*   **5. Gera√ß√£o Robusta (LLM - `generate_response`):** Interage com a API do DeepSeek LLM. Define uma `system_persona` detalhada para emular o Thiago Nigro, incluindo diretrizes para o estilo de resposta. Constr√≥i o prompt completo combinando a pergunta do usu√°rio e o contexto recuperado, enviando-o para o LLM. Utiliza `tenacity` para retries em caso de falhas na API.
*   **6. Utilit√°rios (Hist√≥rico - `convert_history_to_txt`):** Fun√ß√µes auxiliares, como a de converter o hist√≥rico do chat em um formato de texto para download.
*   **7. UI (Streamlit - `main`):** A fun√ß√£o principal que constr√≥i a interface do usu√°rio Streamlit. Inclui o layout da p√°gina, cabe√ßalho com logo, barra lateral para upload de arquivos e gest√£o de conversa (limpar chat, baixar hist√≥rico), e a √°rea de chat onde as perguntas s√£o feitas e as respostas exibidas. Gerencia o estado da sess√£o (`st.session_state`) para persistir dados e mensagens.

### `Transcript_Channel.py` - Script de Coleta de Transcri√ß√µes do YouTube

Este script √© uma ferramenta aut√¥noma para coletar transcri√ß√µes de v√≠deos de um canal espec√≠fico do YouTube, utilizando a API `scrapecreators.com`. Ele √© crucial para a fase de prepara√ß√£o de dados do projeto Primo.AI.

**Principais Se√ß√µes:**

*   **Configura√ß√µes da Miss√£o:** Define vari√°veis chave como `SCRAPECREATORS_API_KEY`, `CHANNEL_HANDLE` (o identificador do canal), `MAX_VIDEOS` (n√∫mero m√°ximo de v√≠deos a coletar) e `SORT_BY` (crit√©rio de ordena√ß√£o: `latest` ou `popular`).
*   **Sess√£o de Requisi√ß√µes Robusta (`create_session_with_retry`):** Cria uma sess√£o HTTP que implementa uma pol√≠tica de retries com backoff exponencial. Isso garante que as chamadas √† API sejam resilientes a falhas de rede ou limita√ß√µes de taxa.
*   **Fase 1: Coletar IDs dos V√≠deos (`fetch_youtube_video_list`):** Conecta-se √† API `scrapecreators.com` para listar os v√≠deos de um dado canal, p√°gina por p√°gina. Ele coleta metadados b√°sicos dos v√≠deos e seus IDs, respeitando o limite de `MAX_VIDEOS` e o crit√©rio `SORT_BY`.
*   **Fase 2: Buscar Transcri√ß√µes (`fetch_video_transcript`):** Para cada v√≠deo coletado na Fase 1, este componente faz uma nova chamada √† API para obter a transcri√ß√£o textual completa. Ele enriquece os dados do v√≠deo com a transcri√ß√£o e filtra quaisquer erros.
*   **Fun√ß√£o Principal (`main`):** Orquestra o fluxo do script. Primeiro, verifica se a chave de API est√° configurada. Em seguida, executa as Fases 1 e 2. Ao final, imprime um relat√≥rio detalhado da miss√£o (tempo total, custos estimados, taxa de sucesso) e salva todas as transcri√ß√µes coletadas e seus metadados em um √∫nico arquivo JSON, que servir√° como entrada para a aplica√ß√£o `app.py`. Utiliza `tqdm` para fornecer feedback de progresso ao usu√°rio.
